# vLLM Configuration for Chat Fast (Qwen3-8B)
# Additional environment variables specific to this model

# Model-specific overrides (optional)
# VLLM_GPU_MEMORY_UTILIZATION=0.85
# VLLM_MAX_NUM_SEQS=512
# VLLM_MAX_NUM_BATCHED_TOKENS=16384

# Performance tuning for faster response
# VLLM_SWAP_SPACE=2
# VLLM_ENABLE_PREFIX_CACHING=true
