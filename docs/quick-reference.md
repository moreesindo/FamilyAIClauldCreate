# FamilyAI å¿«é€Ÿå‚è€ƒæŒ‡å—

Jetson Thor éƒ¨ç½²å’Œè¿ç»´çš„å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥è¡¨

---

## ğŸš€ ä¸€é”®éƒ¨ç½²æµç¨‹

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/FamilyAI.git
cd FamilyAI

# 2. è‡ªåŠ¨é…ç½®ç¯å¢ƒ
chmod +x scripts/00-jetson-setup.sh
./scripts/00-jetson-setup.sh

# 3. é‡æ–°ç™»å½•ï¼ˆæ¿€æ´» Docker ç»„æƒé™ï¼‰
exit
ssh user@jetson-thor-ip

# 4. ä¸‹è½½æ¨¡å‹
cd FamilyAI
./scripts/02-pull-models.sh --batch

# 5. å¯åŠ¨æœåŠ¡
./scripts/03-deploy-docker-compose.sh

# 6. è®¿é—® Web UI
# http://jetson-thor-ip:3000
```

---

## ğŸ“¦ Docker æ“ä½œ

### æœåŠ¡ç®¡ç†

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose up -d

# å¯åŠ¨å®Œæ•´æœåŠ¡ï¼ˆå«ç›‘æ§ï¼‰
docker compose --profile full up -d

# åœæ­¢æ‰€æœ‰æœåŠ¡
docker compose down

# é‡å¯æœåŠ¡
docker compose restart

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker compose ps

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker compose logs -f gateway
docker compose logs -f code-traditional

# é‡å¯å•ä¸ªæœåŠ¡
docker compose restart gateway
```

### èµ„æºç›‘æ§

```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker stats

# å®æ—¶ç›‘æ§
watch -n 2 'docker stats --no-stream'

# æŸ¥çœ‹ GPU ä½¿ç”¨
watch -n 1 nvidia-smi

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
docker system df
```

### æ¸…ç†æ“ä½œ

```bash
# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
docker image prune -a

# æ¸…ç†æ‰€æœ‰æœªä½¿ç”¨èµ„æº
docker system prune -a

# æŸ¥çœ‹é•œåƒåˆ—è¡¨
docker images

# åˆ é™¤ç‰¹å®šé•œåƒ
docker rmi <image-id>
```

---

## ğŸ¤– æ¨¡å‹ç®¡ç†

### ä¸‹è½½æ¨¡å‹

```bash
# æ‰¹é‡ä¸‹è½½æ‰€æœ‰æ¨¡å‹ï¼ˆæ¨èï¼‰
./scripts/02-pull-models.sh --batch

# ä¸‹è½½ç‰¹å®šæ¨¡å‹
./scripts/02-pull-models.sh --model code-traditional
./scripts/02-pull-models.sh --model chat-fast

# ç›´æ¥ä½¿ç”¨ Docker Compose ä¸‹è½½
MODEL_NAME=Qwen/Qwen3-8B-Instruct \
  docker compose -f docker-compose.download.yml run --rm model-downloader
```

### æŸ¥çœ‹æ¨¡å‹

```bash
# æŸ¥çœ‹å·²ä¸‹è½½æ¨¡å‹
ls ~/.cache/huggingface/hub/models--*

# æŸ¥çœ‹æ¨¡å‹ç¼“å­˜å¤§å°
du -sh ~/.cache/huggingface

# æŸ¥çœ‹ç‰¹å®šæ¨¡å‹è¯¦æƒ…
ls -lh ~/.cache/huggingface/hub/models--Qwen--Qwen3-8B-Instruct
```

### æ¸…ç†æ¨¡å‹

```bash
# åˆ é™¤ç‰¹å®šæ¨¡å‹
rm -rf ~/.cache/huggingface/hub/models--<model-name>

# æ¸…ç©ºæ‰€æœ‰æ¨¡å‹ï¼ˆè°¨æ…ï¼ï¼‰
rm -rf ~/.cache/huggingface/hub/models--*
```

---

## ğŸ”§ æœåŠ¡é…ç½®

### ä¿®æ”¹é…ç½®

```bash
# ç¼–è¾‘ç¯å¢ƒå˜é‡
nano .env

# é‡æ–°åŠ è½½é…ç½®
docker compose down
docker compose up -d
```

### å¸¸ç”¨é…ç½®é¡¹

```bash
# ä»£ç†é…ç½®
PROXY_URL=http://127.0.0.1:2526

# GPU å†…å­˜ä½¿ç”¨ç‡ï¼ˆ0.0-1.0ï¼‰
VLLM_GPU_MEMORY_UTILIZATION=0.85

# é‡åŒ–æ–¹æ³•
VLLM_QUANTIZATION=awq

# ç«¯å£é…ç½®
GATEWAY_PORT=8080
WEBUI_PORT=3000
```

### é€‰æ‹©æ€§å¯åŠ¨æœåŠ¡

```bash
# åªå¯åŠ¨è½»é‡çº§æœåŠ¡
docker compose up -d chat-light chat-fast gateway web-ui

# å¯åŠ¨ä»£ç æœåŠ¡
docker compose up -d code-traditional gateway web-ui

# å¯åŠ¨å…¨éƒ¨èŠå¤©æœåŠ¡
docker compose up -d chat-advanced chat-fast chat-light gateway web-ui
```

---

## ğŸŒ API æµ‹è¯•

### å¥åº·æ£€æŸ¥

```bash
# Gateway å¥åº·æ£€æŸ¥
curl http://localhost:8080/health

# åˆ—å‡ºå¯ç”¨æ¨¡å‹
curl http://localhost:8080/v1/models | jq
```

### èŠå¤©æµ‹è¯•

```bash
# ç®€å•èŠå¤©æµ‹è¯•
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "chat-light",
    "messages": [{"role": "user", "content": "ä½ å¥½"}]
  }' | jq

# ä½¿ç”¨ API Key
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "chat-fast",
    "messages": [{"role": "user", "content": "è§£é‡Š Docker"}]
  }' | jq
```

### ä»£ç åŠ©æ‰‹æµ‹è¯•

```bash
# ä»£ç è¡¥å…¨
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "code-traditional",
    "messages": [
      {"role": "user", "content": "å†™ä¸€ä¸ª Python å‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"}
    ]
  }' | jq
```

---

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### è®¿é—®ç›‘æ§ç•Œé¢

```bash
# Prometheus
http://jetson-thor-ip:9090

# Grafana
http://jetson-thor-ip:3001
# ç”¨æˆ·å: admin
# å¯†ç : è§ .env ä¸­çš„ GRAFANA_ADMIN_PASSWORD
```

### æ—¥å¿—ç®¡ç†

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—ï¼ˆæ‰€æœ‰æœåŠ¡ï¼‰
docker compose logs -f

# æŸ¥çœ‹æœ€è¿‘ 100 è¡Œæ—¥å¿—
docker compose logs --tail=100

# æŸ¥çœ‹æœ€è¿‘ 1 å°æ—¶æ—¥å¿—
docker compose logs --since 1h

# æœç´¢é”™è¯¯æ—¥å¿—
docker compose logs | grep -i error

# å¯¼å‡ºæ—¥å¿—
docker compose logs > familyai-$(date +%Y%m%d).log
```

### ç³»ç»Ÿç›‘æ§

```bash
# CPU å’Œå†…å­˜
htop

# GPU ç›‘æ§
nvidia-smi -l 1

# ç£ç›˜ I/O
iostat -x 1

# ç½‘ç»œè¿æ¥
netstat -tulpn | grep -E '(3000|8080)'
```

---

## ğŸ”’ å®‰å…¨ç®¡ç†

### é˜²ç«å¢™

```bash
# æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€
sudo ufw status

# å…è®¸ç«¯å£
sudo ufw allow 3000/tcp
sudo ufw allow 8080/tcp

# åˆ é™¤è§„åˆ™
sudo ufw delete allow 3000/tcp

# é‡æ–°åŠ è½½
sudo ufw reload
```

### å¯†é’¥ç®¡ç†

```bash
# æŸ¥çœ‹å½“å‰ API Key
grep API_KEY .env

# ç”Ÿæˆæ–°çš„ API Key
openssl rand -hex 32

# æ›´æ–° API Keyï¼ˆç¼–è¾‘ .env åé‡å¯ï¼‰
nano .env
docker compose restart gateway
```

---

## ğŸ”„ å¤‡ä»½å’Œæ¢å¤

### å¤‡ä»½

```bash
# å¤‡ä»½é…ç½®
cp .env .env.backup-$(date +%Y%m%d)

# å¤‡ä»½ Web UI æ•°æ®
tar -czf webui-backup-$(date +%Y%m%d).tar.gz data/open-webui/

# å¤‡ä»½æ•´ä¸ªé…ç½®ç›®å½•
tar -czf familyai-config-$(date +%Y%m%d).tar.gz .env docker-compose.yml
```

### æ¢å¤

```bash
# æ¢å¤é…ç½®
cp .env.backup-YYYYMMDD .env

# æ¢å¤ Web UI æ•°æ®
tar -xzf webui-backup-YYYYMMDD.tar.gz

# é‡å¯æœåŠ¡
docker compose down
docker compose up -d
```

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker compose ps

# æ£€æŸ¥ç‰¹å®šå®¹å™¨æ—¥å¿—
docker compose logs <service-name>

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker compose exec <service-name> /bin/bash

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker network ls
docker network inspect familyai_familyai

# æµ‹è¯•æœåŠ¡è¿é€šæ€§
curl -v http://localhost:8080/health
```

### æœåŠ¡é‡å¯

```bash
# å®Œå…¨é‡å¯æ‰€æœ‰æœåŠ¡
docker compose down
docker compose up -d

# é‡å»ºå¹¶å¯åŠ¨ï¼ˆé…ç½®æ›´æ–°åï¼‰
docker compose down
docker compose up -d --build

# å¼ºåˆ¶é‡æ–°åˆ›å»ºå®¹å™¨
docker compose up -d --force-recreate
```

### æ€§èƒ½é—®é¢˜

```bash
# é™ä½ GPU å†…å­˜ä½¿ç”¨
# ç¼–è¾‘ .env: VLLM_GPU_MEMORY_UTILIZATION=0.8

# å‡å°‘è¿è¡Œçš„æ¨¡å‹
docker compose stop code-agentic chat-advanced

# æŸ¥çœ‹èµ„æºç“¶é¢ˆ
docker stats
nvidia-smi
```

---

## ğŸ”§ ç»´æŠ¤ä»»åŠ¡

### å®šæœŸæ¸…ç†

```bash
# æ¯å‘¨æ¸…ç†æœªä½¿ç”¨èµ„æº
docker system prune -f

# æ¯æœˆæ¸…ç†æ—¥å¿—
docker compose down
find logs/ -type f -mtime +30 -delete
docker compose up -d
```

### æ›´æ–°é•œåƒ

```bash
# æ‹‰å–æœ€æ–°é•œåƒ
docker compose pull

# é‡å¯æœåŠ¡
docker compose down
docker compose up -d
```

### æ£€æŸ¥æ›´æ–°

```bash
# æ£€æŸ¥ Docker ç‰ˆæœ¬
docker --version

# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ç³»ç»Ÿæ›´æ–°
sudo apt update
sudo apt list --upgradable
```

---

## ğŸ“± å®¢æˆ·ç«¯é…ç½®

### VS Code (Continue)

é…ç½®æ–‡ä»¶: `~/.continue/config.json`

```json
{
  "models": [
    {
      "title": "FamilyAI Code",
      "provider": "openai",
      "model": "code-traditional",
      "apiBase": "http://jetson-thor-ip:8080/v1",
      "apiKey": "YOUR_API_KEY"
    }
  ]
}
```

### Curl æµ‹è¯•æ¨¡æ¿

```bash
#!/bin/bash
API_BASE="http://jetson-thor-ip:8080"
API_KEY="your-api-key"

curl -X POST "$API_BASE/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_KEY" \
  -d '{
    "model": "auto",
    "messages": [
      {"role": "user", "content": "ä½ çš„é—®é¢˜"}
    ],
    "temperature": 0.7
  }' | jq
```

---

## ğŸ“ è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹è„šæœ¬å¸®åŠ©
./scripts/02-pull-models.sh --help
./scripts/03-deploy-docker-compose.sh --help

# æŸ¥çœ‹å®Œæ•´æ–‡æ¡£
cat docs/jetson-thor-deployment.md

# æŸ¥çœ‹æ—¥å¿—
less logs/familyai.log
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–æç¤º

1. **GPU å†…å­˜ä¼˜åŒ–**: è°ƒæ•´ `VLLM_GPU_MEMORY_UTILIZATION` åœ¨ 0.80-0.90 ä¹‹é—´
2. **æŒ‰éœ€å¯åŠ¨**: ä¸è¦åŒæ—¶è¿è¡Œæ‰€æœ‰æ¨¡å‹ï¼Œæ ¹æ®å®é™…ä½¿ç”¨å¯åŠ¨
3. **é‡åŒ–é€‰æ‹©**: INT4 (awq) èŠ‚çœå†…å­˜ï¼ŒFP8 æå‡ç²¾åº¦
4. **å¹¶å‘æ§åˆ¶**: é€šè¿‡ Gateway çš„ rate limiting æ§åˆ¶å¹¶å‘
5. **ç¼“å­˜é¢„çƒ­**: ç³»ç»Ÿå¯åŠ¨åå‘é€å‡ æ¬¡æµ‹è¯•è¯·æ±‚é¢„çƒ­æ¨¡å‹

---

**å¿«é€Ÿå‚è€ƒå®Œæ¯•ï¼æ›´å¤šè¯¦æƒ…è¯·æŸ¥é˜…å®Œæ•´æ–‡æ¡£ã€‚** ğŸ“š
